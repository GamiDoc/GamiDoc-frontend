{"ast":null,"code":"var Query = require('./queries');\n\nvar Operator = require('./operators');\n\nvar NUMBERS = /[0-9]/;\nvar LETTERS = /[a-z|\\-]/i;\nvar WHITESPACE = /\\s/;\nvar COLON = /:/;\nvar COMMA = /,/;\nvar AND = /and$/;\nvar AT = /@/;\n\nfunction tokenizer(input) {\n  var current = 0;\n  var tokens = [];\n\n  while (current < input.length) {\n    var char = input[current];\n\n    if (AT.test(char)) {\n      char = input[++current];\n\n      while (LETTERS.test(char) && char !== undefined) {\n        char = input[++current];\n      }\n    }\n\n    if (WHITESPACE.test(char) || char === ')' || char === '(') {\n      current++;\n      continue;\n    }\n\n    if (COLON.test(char) || COMMA.test(char)) {\n      current++;\n      tokens.push({\n        type: 'operator',\n        value: char\n      });\n      continue;\n    }\n\n    if (NUMBERS.test(char)) {\n      var value = '';\n\n      while (NUMBERS.test(char)) {\n        value += char;\n        char = input[++current];\n      }\n\n      tokens.push({\n        type: 'number',\n        value: value\n      });\n      continue;\n    }\n\n    if (LETTERS.test(char)) {\n      var value = '';\n\n      while (LETTERS.test(char) && char !== undefined) {\n        value += char;\n        char = input[++current];\n      }\n\n      if (AND.test(value)) {\n        tokens.push({\n          type: 'operator',\n          value: value\n        });\n      } else {\n        tokens.push({\n          type: 'literal',\n          value: value\n        });\n      }\n\n      continue;\n    }\n\n    throw new TypeError('Tokenizer: I dont know what this character is: ' + char);\n  }\n\n  return tokens;\n}\n\nfunction parser(tokens) {\n  var output = [];\n  var stack = [];\n\n  while (tokens.length > 0) {\n    var token = tokens.shift();\n\n    if (token.type === 'number' || token.type === 'literal') {\n      output.push(token);\n      continue;\n    }\n\n    if (token.type === 'operator') {\n      if (COLON.test(token.value)) {\n        token = {\n          type: 'query',\n          key: output.pop(),\n          value: tokens.shift()\n        };\n        output.push(token);\n        continue;\n      }\n\n      while (stack.length > 0) {\n        output.unshift(stack.pop());\n      }\n\n      stack.push(token);\n    }\n  }\n\n  while (stack.length > 0) {\n    output.unshift(stack.pop());\n  }\n\n  function walk() {\n    var head = output.shift();\n\n    if (head.type === 'number') {\n      return parseInt(head.value);\n    }\n\n    if (head.type === 'literal') {\n      return head.value;\n    }\n\n    if (head.type === 'operator') {\n      var l = walk();\n      var r = walk();\n      return Operator(head.value, l, r);\n    }\n\n    if (head.type === 'query') {\n      var l = head.key.value;\n      var r = head.value.value;\n      return Query(l, r);\n    }\n  }\n\n  return walk();\n}\n\nmodule.exports = {\n  parse: function (query) {\n    var tokens = tokenizer(query);\n    var ast = parser(tokens);\n    return ast;\n  }\n};","map":{"version":3,"names":["Query","require","Operator","NUMBERS","LETTERS","WHITESPACE","COLON","COMMA","AND","AT","tokenizer","input","current","tokens","length","char","test","undefined","push","type","value","TypeError","parser","output","stack","token","shift","key","pop","unshift","walk","head","parseInt","l","r","module","exports","parse","query","ast"],"sources":["/home/carlobottaro/Documents/Universit√†/gamification/node_modules/media-engine/src/parser.js"],"sourcesContent":["var Query = require('./queries');\nvar Operator = require('./operators');\n\nvar NUMBERS = /[0-9]/;\nvar LETTERS = /[a-z|\\-]/i;\nvar WHITESPACE = /\\s/;\nvar COLON = /:/;\nvar COMMA = /,/;\nvar AND = /and$/;\nvar AT = /@/;\n\nfunction tokenizer(input) {\n  var current = 0;\n  var tokens = [];\n\n  while (current < input.length) {\n    var char = input[current];\n\n    if (AT.test(char)) {\n      char = input[++current];\n      while (LETTERS.test(char) && char !== undefined) {\n        char = input[++current];\n      }\n    }\n\n    if (WHITESPACE.test(char) || char === ')' || char === '(') {\n      current++;\n      continue;\n    }\n\n    if (COLON.test(char) || COMMA.test(char)) {\n      current++;\n      tokens.push({ type: 'operator', value: char });\n      continue;\n    }\n\n    if (NUMBERS.test(char)) {\n      var value = '';\n      while (NUMBERS.test(char)) {\n        value += char;\n        char = input[++current];\n      }\n\n      tokens.push({ type: 'number', value: value });\n      continue;\n    }\n\n    if (LETTERS.test(char)) {\n      var value = '';\n      while (LETTERS.test(char) && char !== undefined) {\n        value += char;\n        char = input[++current];\n      }\n      if (AND.test(value)) {\n        tokens.push({ type: 'operator', value: value });\n      } else {\n        tokens.push({ type: 'literal', value: value });\n      }\n\n      continue;\n    }\n\n    throw new TypeError(\n      'Tokenizer: I dont know what this character is: ' + char\n    );\n  }\n\n  return tokens;\n}\n\nfunction parser(tokens) {\n  var output = [];\n  var stack = [];\n\n  while (tokens.length > 0) {\n    var token = tokens.shift();\n\n    if (token.type === 'number' || token.type === 'literal') {\n      output.push(token);\n      continue;\n    }\n\n    if (token.type === 'operator') {\n      if (COLON.test(token.value)) {\n        token = { type: 'query', key: output.pop(), value: tokens.shift() };\n        output.push(token);\n        continue;\n      }\n\n      while (stack.length > 0) {\n        output.unshift(stack.pop());\n      }\n      stack.push(token);\n    }\n  }\n\n  while (stack.length > 0) {\n    output.unshift(stack.pop());\n  }\n\n  function walk() {\n    var head = output.shift();\n\n    if (head.type === 'number') {\n      return parseInt(head.value);\n    }\n\n    if (head.type === 'literal') {\n      return head.value;\n    }\n\n    if (head.type === 'operator') {\n      var l = walk();\n      var r = walk();\n\n      return Operator(head.value, l, r);\n    }\n\n    if (head.type === 'query') {\n      var l = head.key.value;\n      var r = head.value.value;\n\n      return Query(l, r);\n    }\n  }\n\n  return walk();\n}\n\nmodule.exports = {\n  parse: function(query) {\n    var tokens = tokenizer(query);\n    var ast = parser(tokens);\n    return ast;\n  }\n};\n"],"mappings":"AAAA,IAAIA,KAAK,GAAGC,OAAO,CAAC,WAAD,CAAnB;;AACA,IAAIC,QAAQ,GAAGD,OAAO,CAAC,aAAD,CAAtB;;AAEA,IAAIE,OAAO,GAAG,OAAd;AACA,IAAIC,OAAO,GAAG,WAAd;AACA,IAAIC,UAAU,GAAG,IAAjB;AACA,IAAIC,KAAK,GAAG,GAAZ;AACA,IAAIC,KAAK,GAAG,GAAZ;AACA,IAAIC,GAAG,GAAG,MAAV;AACA,IAAIC,EAAE,GAAG,GAAT;;AAEA,SAASC,SAAT,CAAmBC,KAAnB,EAA0B;EACxB,IAAIC,OAAO,GAAG,CAAd;EACA,IAAIC,MAAM,GAAG,EAAb;;EAEA,OAAOD,OAAO,GAAGD,KAAK,CAACG,MAAvB,EAA+B;IAC7B,IAAIC,IAAI,GAAGJ,KAAK,CAACC,OAAD,CAAhB;;IAEA,IAAIH,EAAE,CAACO,IAAH,CAAQD,IAAR,CAAJ,EAAmB;MACjBA,IAAI,GAAGJ,KAAK,CAAC,EAAEC,OAAH,CAAZ;;MACA,OAAOR,OAAO,CAACY,IAAR,CAAaD,IAAb,KAAsBA,IAAI,KAAKE,SAAtC,EAAiD;QAC/CF,IAAI,GAAGJ,KAAK,CAAC,EAAEC,OAAH,CAAZ;MACD;IACF;;IAED,IAAIP,UAAU,CAACW,IAAX,CAAgBD,IAAhB,KAAyBA,IAAI,KAAK,GAAlC,IAAyCA,IAAI,KAAK,GAAtD,EAA2D;MACzDH,OAAO;MACP;IACD;;IAED,IAAIN,KAAK,CAACU,IAAN,CAAWD,IAAX,KAAoBR,KAAK,CAACS,IAAN,CAAWD,IAAX,CAAxB,EAA0C;MACxCH,OAAO;MACPC,MAAM,CAACK,IAAP,CAAY;QAAEC,IAAI,EAAE,UAAR;QAAoBC,KAAK,EAAEL;MAA3B,CAAZ;MACA;IACD;;IAED,IAAIZ,OAAO,CAACa,IAAR,CAAaD,IAAb,CAAJ,EAAwB;MACtB,IAAIK,KAAK,GAAG,EAAZ;;MACA,OAAOjB,OAAO,CAACa,IAAR,CAAaD,IAAb,CAAP,EAA2B;QACzBK,KAAK,IAAIL,IAAT;QACAA,IAAI,GAAGJ,KAAK,CAAC,EAAEC,OAAH,CAAZ;MACD;;MAEDC,MAAM,CAACK,IAAP,CAAY;QAAEC,IAAI,EAAE,QAAR;QAAkBC,KAAK,EAAEA;MAAzB,CAAZ;MACA;IACD;;IAED,IAAIhB,OAAO,CAACY,IAAR,CAAaD,IAAb,CAAJ,EAAwB;MACtB,IAAIK,KAAK,GAAG,EAAZ;;MACA,OAAOhB,OAAO,CAACY,IAAR,CAAaD,IAAb,KAAsBA,IAAI,KAAKE,SAAtC,EAAiD;QAC/CG,KAAK,IAAIL,IAAT;QACAA,IAAI,GAAGJ,KAAK,CAAC,EAAEC,OAAH,CAAZ;MACD;;MACD,IAAIJ,GAAG,CAACQ,IAAJ,CAASI,KAAT,CAAJ,EAAqB;QACnBP,MAAM,CAACK,IAAP,CAAY;UAAEC,IAAI,EAAE,UAAR;UAAoBC,KAAK,EAAEA;QAA3B,CAAZ;MACD,CAFD,MAEO;QACLP,MAAM,CAACK,IAAP,CAAY;UAAEC,IAAI,EAAE,SAAR;UAAmBC,KAAK,EAAEA;QAA1B,CAAZ;MACD;;MAED;IACD;;IAED,MAAM,IAAIC,SAAJ,CACJ,oDAAoDN,IADhD,CAAN;EAGD;;EAED,OAAOF,MAAP;AACD;;AAED,SAASS,MAAT,CAAgBT,MAAhB,EAAwB;EACtB,IAAIU,MAAM,GAAG,EAAb;EACA,IAAIC,KAAK,GAAG,EAAZ;;EAEA,OAAOX,MAAM,CAACC,MAAP,GAAgB,CAAvB,EAA0B;IACxB,IAAIW,KAAK,GAAGZ,MAAM,CAACa,KAAP,EAAZ;;IAEA,IAAID,KAAK,CAACN,IAAN,KAAe,QAAf,IAA2BM,KAAK,CAACN,IAAN,KAAe,SAA9C,EAAyD;MACvDI,MAAM,CAACL,IAAP,CAAYO,KAAZ;MACA;IACD;;IAED,IAAIA,KAAK,CAACN,IAAN,KAAe,UAAnB,EAA+B;MAC7B,IAAIb,KAAK,CAACU,IAAN,CAAWS,KAAK,CAACL,KAAjB,CAAJ,EAA6B;QAC3BK,KAAK,GAAG;UAAEN,IAAI,EAAE,OAAR;UAAiBQ,GAAG,EAAEJ,MAAM,CAACK,GAAP,EAAtB;UAAoCR,KAAK,EAAEP,MAAM,CAACa,KAAP;QAA3C,CAAR;QACAH,MAAM,CAACL,IAAP,CAAYO,KAAZ;QACA;MACD;;MAED,OAAOD,KAAK,CAACV,MAAN,GAAe,CAAtB,EAAyB;QACvBS,MAAM,CAACM,OAAP,CAAeL,KAAK,CAACI,GAAN,EAAf;MACD;;MACDJ,KAAK,CAACN,IAAN,CAAWO,KAAX;IACD;EACF;;EAED,OAAOD,KAAK,CAACV,MAAN,GAAe,CAAtB,EAAyB;IACvBS,MAAM,CAACM,OAAP,CAAeL,KAAK,CAACI,GAAN,EAAf;EACD;;EAED,SAASE,IAAT,GAAgB;IACd,IAAIC,IAAI,GAAGR,MAAM,CAACG,KAAP,EAAX;;IAEA,IAAIK,IAAI,CAACZ,IAAL,KAAc,QAAlB,EAA4B;MAC1B,OAAOa,QAAQ,CAACD,IAAI,CAACX,KAAN,CAAf;IACD;;IAED,IAAIW,IAAI,CAACZ,IAAL,KAAc,SAAlB,EAA6B;MAC3B,OAAOY,IAAI,CAACX,KAAZ;IACD;;IAED,IAAIW,IAAI,CAACZ,IAAL,KAAc,UAAlB,EAA8B;MAC5B,IAAIc,CAAC,GAAGH,IAAI,EAAZ;MACA,IAAII,CAAC,GAAGJ,IAAI,EAAZ;MAEA,OAAO5B,QAAQ,CAAC6B,IAAI,CAACX,KAAN,EAAaa,CAAb,EAAgBC,CAAhB,CAAf;IACD;;IAED,IAAIH,IAAI,CAACZ,IAAL,KAAc,OAAlB,EAA2B;MACzB,IAAIc,CAAC,GAAGF,IAAI,CAACJ,GAAL,CAASP,KAAjB;MACA,IAAIc,CAAC,GAAGH,IAAI,CAACX,KAAL,CAAWA,KAAnB;MAEA,OAAOpB,KAAK,CAACiC,CAAD,EAAIC,CAAJ,CAAZ;IACD;EACF;;EAED,OAAOJ,IAAI,EAAX;AACD;;AAEDK,MAAM,CAACC,OAAP,GAAiB;EACfC,KAAK,EAAE,UAASC,KAAT,EAAgB;IACrB,IAAIzB,MAAM,GAAGH,SAAS,CAAC4B,KAAD,CAAtB;IACA,IAAIC,GAAG,GAAGjB,MAAM,CAACT,MAAD,CAAhB;IACA,OAAO0B,GAAP;EACD;AALc,CAAjB"},"metadata":{},"sourceType":"script"}